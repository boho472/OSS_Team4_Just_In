import os
import sys
import json
import numpy as np
from pathlib import Path
from PIL import Image
import torch

# DAM4SAM import
from tracking_wrapper_mot import DAM4SAMMOT


def create_dummy_image(output_dir, n_frames=30, img_size=(1024, 1024)):
    """
    í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±

    Args:
        output_dir: ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ
        n_frames: ìƒì„±í•  í”„ë ˆì„ ìˆ˜
        img_size: ì´ë¯¸ì§€ í¬ê¸°(width, height)
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)

    print(f"Creating {n_frames} dummy images in '{output_dir}/'...")

    for frame_idx in range(n_frames):
        # ê°„ë‹¨í•œ ê·¸ë¼ë””ì–¸íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        img = np.zeros((*img_size[::-1], 3), dtype=np.uint8)

        # ë°°ê²½ ê·¸ë¼ë””ì–¸íŠ¸
        for y in range(img_size[1]):
            img[y::, :] = int(255 * y / img_size[1])

        # ê°ì²´ë“¤ì„ ì‹œë®¬ë ˆì´ì…˜ í•˜ê¸° ìœ„í•´ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        # ê°ì²´1: ê³„ì† ë³´ì´ëŠ” ìƒí™©
        x1, y1 = 100 + frame_idx, 100
        cv2_rectangle(img, x1, y1, 50, 50, (255, 0, 0))

        # ê°ì²´2: 0~3, 22~29
        if 0 <= frame_idx <= 3 or frame_idx >= 22:
            x2, y2 = 200, 150
            cv2_rectangle(img, x2, y2, 60, 60, (0, 255, 0))

        # ê°ì²´ 3: 0~7, 26~29
        if 0 <= frame_idx <= 7 or frame_idx >= 26:
            x3, y3 = 300, 300
            cv2_rectangle(img, x3, y3, 55, 55, (0, 255, 255))

        # ê°ì²´ 4: 0~10, 21~29
        if 0 <= frame_idx <= 10 or frame_idx >= 21:
            x4, y4 = 400, 100
            cv2_rectangle(img, x4, y4, 45, 45, (255, 255, 0))

        # ê°ì²´ 5: 25~29
        if frame_idx >= 25:
            x5, y5 = 500, 300
            cv2_rectangle(img, x5, y5, 70, 70, (255, 0, 255))

        # PIL Imageë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        pil_img = Image.fromarray(img)
        img_path = output_dir / f"frame_{frame_idx:06d}.jpg"
        pil_img.save(img_path)

    print(f"âœ… Created {n_frames} images")


def cv2_rectangle(img, x, y, w, h, color):
    """OpenCV ì—†ì´ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°"""
    img[y:y+h, x:x+h] = color


def run_test():
    """í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
    print("="*80)
    print("DAM4SAM with HybridTrack JSON Integeration Test")
    print("="*80)

    # ê²½ë¡œ ì„¤ì •
    json_dir = Path("test_jsons")
    image_dir = Path("test_images")

    # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
    create_dummy_image(image_dir, n_frames=30)

    # DAM4SAM ì´ˆê¸°í™”
    print("\n[1] Initializing DAM4SAM...")
    checkpoint_path = os.path.join(os.getcwd(), "checkpoints")
    tracker = DAM4SAMMOT(
        model_size='tiny',
        checkpoint_dir=checkpoint_path
    )
    print("âœ… DAM4SAM Initialized")

    # 30ê°œ í”„ë ˆì„ ì²˜ë¦¬
    print("\n[2] Processing 30 frames...")
    print("-"*80)

    for frame_idx in range(30):
        # JSON íŒŒì¼ ê²½ë¡œ
        json_path = json_dir / f"frame_{frame_idx:06d}.json"

        # ì´ë¯¸ì§€ ë¡œë“œ
        img_path = image_dir / f"frame_{frame_idx:06d}.jpg"
        image = Image.open(img_path)

        print(f"\nğŸš© Frame {frame_idx:03d}")
        print(f"     JSON: {json_path.name}")
        print(f"     Image: {img_path.name}")

        # JSON ì½ì–´ì„œ HT ê²°ê³¼ í™•ì¸
        with open(json_path, 'r') as f:
            frame_data = json.load(f)

        ht_results = frame_data['dam4sam_tracking']['HybridTrack_results']
        print(f"   HT detected {len(ht_results)} objects:")
        for ht_obj in ht_results:
            print(
                f"       - obj_id={ht_obj['object_id']}, bbox={ht_obj['bbox']}")

        # DAM4SAM ì²˜ë¦¬
        outputs = tracker.process_frame_with_ht_json(
            frame_idx, json_path, image)

        # ê²°ê³¼ ì¶œë ¥
        print(f"   DAM4SAM tracking {len(outputs['masks'])} objects")

        # JSONì— ì €ì¥ëœ ê²°ê³¼ í™•ì¸
        with open(json_path, 'r') as f:
            updated_data = json.load(f)

        dam_results = updated_data['dam4sam_tracking']['DAM4SAM_results']
        print(f"   DAM4SAM results saved: {len(dam_results)} objects")
        for dam_obj in dam_results:
            print(f"   - internal_id={dam_obj['internal_id']}, "
                  f"bbox={dam_obj['bbox']}, pixels={dam_obj['mask_pixels']}")

    print("\n" + "="*80)
    print("ğŸ‰ Test ì™„ë£Œ!")
    print("="*80)

    # ì£¼ìš” í”„ë ˆì„ ê²°ê³¼ í™•ì¸
    print("\nì£¼ìš” í”„ë ˆì„ ê²°ê³¼ í™•ì¸:")
    print("="*80)

    key_frames = [0, 3, 4, 21, 22, 25, 26]

    for frame_idx in key_frames:
        json_path = json_dir / f"frame_{frame_idx:06d}.json"
        with open(json_path, 'r') as f:
            data = json.load(f)

        ht_count = len(data['dam4sam_tracking']['HybridTrack_results'])
        dam_count = len(data['dam4sam_tracking']['DAM4SAM_results'])

        print(f"\nFrame {frame_idx:03d}")
        print(f"   HT objects: {ht_count}")
        print(f"   DAM objects: {dam_count}")

        if frame_idx == 22:
            print("   âš¡Expected: obj_id=6 should be FILTERED (ID switching)")
            ht_obj_6 = [obj for obj in data['dam4sam_tracking']['HybridTrack_results']
                        if obj['object_id'] == 6]
            if ht_obj_6:
                print(f"     HT detected obj_id=6: {ht_obj_6[0]['bbox']}")
            print(
                f"     DAM tracking {dam_count} objects (should NOT increase)")

        if frame_idx == 26:
            print("   âš¡Expected: obj_id=7 should be FILTERED (ID switching)")
            ht_obj_7 = [obj for obj in data['dam4sam_tracking']['HybridTrack_results']
                        if obj['object_id'] == 7]
            if ht_obj_7:
                print(f"   HT detected obj_id=7: {ht_obj_7[0]['bbox']}")
            print(f"   DAM tracking {dam_count} objects (should NOT increase)")

    print("\n" + "=*80")


if __name__ == "__main__":
    # CUDA ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
    if not torch.cuda.is_available():
        print("Warning: CUDA not available. Using CPU (will be slow)")

    run_test()
